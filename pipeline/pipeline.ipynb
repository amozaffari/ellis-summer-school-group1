{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a3cfda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_era5_lai_whole.py\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa592016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_era5_lai_whole.py\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ERA5LAIWholeWorld(Dataset):\n",
    "    \"\"\"\n",
    "    One YEAR, 24 items (one per 15-day sample). Each __getitem__ returns:\n",
    "        X: (3, H, W)  -> [ssrd, t2m, tp]  (raw/anom/z as chosen)\n",
    "        y: (1, H, W)  -> LAI (raw or anomaly)\n",
    "        mask: (1, H, W) boolean (True where y is valid)\n",
    "        meta: dict with 'year' and 'sample'\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        year: int,\n",
    "        era5_mode=\"anom\",   # \"raw\" | \"anom\" | \"z\"\n",
    "        lai_mode=\"raw\",     # \"raw\" | \"anom\"\n",
    "        paths=None,\n",
    "        engine=\"netcdf4\",\n",
    "        robust_nan=True,\n",
    "        sample_indices=None,  # default: all 0..23\n",
    "    ):\n",
    "        assert era5_mode in (\"raw\",\"anom\",\"z\")\n",
    "        assert lai_mode in (\"raw\",\"anom\")\n",
    "        self.year = int(year)\n",
    "        self.era5_mode = era5_mode\n",
    "        self.lai_mode = lai_mode\n",
    "        self.engine = engine\n",
    "        self.robust_nan = robust_nan\n",
    "        self.sample_indices = list(range(24)) if sample_indices is None else list(sample_indices)\n",
    "\n",
    "        # default paths (override with 'paths' dict)\n",
    "        default_paths = {\n",
    "            \"era5_root\": \"/ptmp/mp002/ellis/lai\",\n",
    "            \"era5_anom_dir\": \"/ptmp/mp040/outputdir/era5/anom\",   # your anomalies/z-scores\n",
    "            \"lai_root\": \"/ptmp/mp002/ellis/lai/lai\",\n",
    "            \"lai_tmpl\": \"LAI.1440.720.{year}.nc\",\n",
    "            \"lai_anom_dir\": \"/ptmp/mp002/ellis/lai/anom\",         # change if different\n",
    "        }\n",
    "        self.paths = default_paths if paths is None else {**default_paths, **paths}\n",
    "\n",
    "        # open all arrays for that year\n",
    "        self._open_year()\n",
    "\n",
    "    def _open_da(self, path, varname):\n",
    "        ds = xr.open_dataset(path, engine=self.engine)\n",
    "        da = ds[varname]\n",
    "        if self.robust_nan:\n",
    "            fv = da.attrs.get(\"_FillValue\", None)\n",
    "            if fv is not None:\n",
    "                da = da.where(da != fv)\n",
    "        # north-up\n",
    "        lat_name = \"lat\" if \"lat\" in da.coords else \"latitude\"\n",
    "        da = da.sortby(lat_name)\n",
    "        # attach sample coord\n",
    "        if \"time\" in da.dims and da.sizes[\"time\"] == 24:\n",
    "            da = da.assign_coords(sample=(\"time\", np.arange(24)))\n",
    "        return da\n",
    "\n",
    "    def _open_year(self):\n",
    "        y = self.year\n",
    "\n",
    "        # ERA5 inputs\n",
    "        if self.era5_mode == \"raw\":\n",
    "            f_ssrd = os.path.join(self.paths[\"era5_root\"], \"ssrd\", f\"ssrd.15daily.fc.era5.1440.720.{y}.nc\")\n",
    "            f_t2m  = os.path.join(self.paths[\"era5_root\"], \"t2m\",  f\"t2m.15daily.an.era5.1440.720.{y}.nc\")\n",
    "            f_tp   = os.path.join(self.paths[\"era5_root\"], \"tp\",   f\"tp.15daily.fc.era5.1440.720.{y}.nc\")\n",
    "            self.ssrd = self._open_da(f_ssrd, \"ssrd\")\n",
    "            self.t2m  = self._open_da(f_t2m,  \"t2m\")\n",
    "            self.tp   = self._open_da(f_tp,   \"tp\")\n",
    "        else:\n",
    "            suffix = \"anom\" if self.era5_mode == \"anom\" else \"z\"\n",
    "            base = self.paths[\"era5_anom_dir\"]\n",
    "            self.ssrd = self._open_da(os.path.join(base, f\"ssrd_{suffix}_{y}.nc\"), f\"ssrd_{suffix}\")\n",
    "            self.t2m  = self._open_da(os.path.join(base, f\"t2m_{suffix}_{y}.nc\"),  f\"t2m_{suffix}\")\n",
    "            self.tp   = self._open_da(os.path.join(base, f\"tp_{suffix}_{y}.nc\"),   f\"tp_{suffix}\")\n",
    "\n",
    "        # LAI target\n",
    "        lai_file = os.path.join(self.paths[\"lai_root\"], self.paths[\"lai_tmpl\"].format(year=y))\n",
    "        lai_var = self._infer_var(lai_file)\n",
    "        self.lai = self._open_da(lai_file, lai_var)\n",
    "\n",
    "        if self.lai_mode == \"anom\":\n",
    "            # use your saved LAI anomalies per year if available\n",
    "            lai_anom_dir = self.paths.get(\"lai_anom_dir\", self.paths[\"lai_root\"])\n",
    "            lai_anom_file = os.path.join(lai_anom_dir, f\"LAI_anom_{y}.nc\")\n",
    "            if os.path.exists(lai_anom_file):\n",
    "                self.lai = self._open_da(lai_anom_file, \"LAI_anom\")\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"LAI anomaly file not found: {lai_anom_file}\")\n",
    "\n",
    "        # dims/coords\n",
    "        self.lat_name = \"lat\" if \"lat\" in self.lai.coords else \"latitude\"\n",
    "        self.lon_name = \"lon\" if \"lon\" in self.lai.coords else \"longitude\"\n",
    "\n",
    "        # sanity checks\n",
    "        for da, name in [(self.ssrd,\"ssrd\"),(self.t2m,\"t2m\"),(self.tp,\"tp\")]:\n",
    "            assert \"time\" in da.dims and da.sizes[\"time\"] == 24, f\"{name} expects 24 samples\"\n",
    "            assert da.sizes[self.lat_name] == self.lai.sizes[self.lat_name]\n",
    "            assert da.sizes[self.lon_name] == self.lai.sizes[self.lon_name]\n",
    "        assert \"time\" in self.lai.dims and self.lai.sizes[\"time\"] == 24\n",
    "\n",
    "    def _infer_var(self, nc_path):\n",
    "        with xr.open_dataset(nc_path, engine=self.engine) as ds:\n",
    "            for v in ds.data_vars:\n",
    "                if ds[v].ndim >= 2:\n",
    "                    return v\n",
    "        raise RuntimeError(f\"No data variable in {nc_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        s = self.sample_indices[i]\n",
    "        # features (H,W) each\n",
    "        x_ssrd = self.ssrd.isel(time=s).values\n",
    "        x_t2m  = self.t2m .isel(time=s).values\n",
    "        x_tp   = self.tp  .isel(time=s).values\n",
    "        # target\n",
    "        y_lai  = self.lai .isel(time=s).values  # may contain NaNs over ocean\n",
    "\n",
    "        # stack to tensors, channel-first\n",
    "        X = np.stack([x_ssrd, x_t2m, x_tp], axis=0)              # (3,H,W)\n",
    "        y = np.expand_dims(y_lai, axis=0)                       # (1,H,W)\n",
    "        mask = ~np.isnan(y)                                     # valid target pixels\n",
    "\n",
    "        # features: fill NaNs with 0 (or choose another fill)\n",
    "        X = np.nan_to_num(X, nan=0.0)\n",
    "\n",
    "        X = torch.from_numpy(X.astype(np.float32))\n",
    "        y = torch.from_numpy(np.nan_to_num(y, nan=0.0).astype(np.float32))\n",
    "        mask = torch.from_numpy(mask.astype(np.bool_))\n",
    "        meta = {\"year\": self.year, \"sample\": int(s)}\n",
    "        return X, y, mask, meta\n",
    "\n",
    "# Loss helper (same as before)\n",
    "def masked_mse_loss(pred, target, mask):\n",
    "    diff2 = (pred - target) ** 2\n",
    "    diff2 = diff2 * mask.float()\n",
    "    denom = mask.float().sum().clamp_min(1.0)\n",
    "    return diff2.sum() / denom\n",
    "\n",
    "def collate_keep_meta(batch):\n",
    "    \"\"\"Custom collate so that 'meta' stays a list of dicts (not collated into tensors).\"\"\"\n",
    "    Xs, ys, masks, metas = zip(*batch)\n",
    "    return torch.stack(Xs), torch.stack(ys), torch.stack(masks), list(metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e395b665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year=1990, sample=0, loss=166.4673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113026/1729101369.py:28: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n",
      "  print(f\"year={meta['year'][0].item()}, sample={meta['sample'][0].item()}, loss={float(loss):.4f}\")\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "ds = ERA5LAIWholeWorld(\n",
    "    year=1990,\n",
    "    era5_mode=\"raw\",   # or \"raw\"/\"z\"\n",
    "    lai_mode=\"raw\",     # or \"anom\"\n",
    "    paths={\n",
    "        \"era5_root\": \"/ptmp/mp002/ellis/lai\",\n",
    "        \"era5_anom_dir\": \"/ptmp/mp040/outputdir/era5/anom\",\n",
    "        \"lai_root\": \"/ptmp/mp002/ellis/lai/lai\",\n",
    "        \"lai_tmpl\": \"LAI.1440.720.{year}.nc\",\n",
    "        # \"lai_anom_dir\": \"/ptmp/mp002/ellis/lai/anom\",  # if using LAI anomalies\n",
    "    },\n",
    ")\n",
    "\n",
    "loader = DataLoader(ds, batch_size=1, shuffle=False)  # batch_size=1 since each item is full globe\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 1, 3, padding=1)\n",
    ")\n",
    "\n",
    "for X, y, mask, meta in loader:\n",
    "    pred = model(X)\n",
    "    loss = masked_mse_loss(pred, y, mask)\n",
    "    print(f\"year={meta['year'][0].item()}, sample={meta['sample'][0].item()}, loss={float(loss):.4f}\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ellis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
